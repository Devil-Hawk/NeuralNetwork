ankit@DVH-PC MINGW64 ~/desktop/ankit_punjabi-dsci_640/pa3/pa3 (main)
$ java GradientDescent mnist lenet5 xavier 500 softmax 50 0.2 0.0005 0.95 0 0 0 1 0.1 | tee mnist_99.txt
Log level set to INFO
[INFO   ] inputDropoutRate: 0.0, hiddenDropoutRate: 0.0
[INFO   ] reading image filename './datasets/train-images-idx3-ubyte' and label filename: './datasets/train-labels-idx1-ubyte
[INFO   ] read 60000 MNIST images.
[INFO   ] reading image filename './datasets/t10k-images-idx3-ubyte' and label filename: './datasets/t10k-labels-idx1-ubyte
[INFO   ] read 10000 MNIST images.
[INFO   ] Using an SOFTMAX loss function.
[INFO   ] Starting minibatch gradient descent!
[INFO   ] minibatch (500), mnist, softmax, lr: 5.0E-4, mu:0.95
[INFO   ] calculating initial error and accuracy
[INFO   ] bestError error accuracy testingError testingAccuracy
ITERATION  138412.70186081517 138412.70186081517    9.93000 23066.891202722298  10.32000
[INFO   ] Learning rate: 4.875E-4
  2920.340230827817 2920.340230827817   98.41833 547.689412355968  98.28000
[INFO   ] Learning rate: 4.753125E-4
  1812.021246483643 1812.021246483643   99.04833 479.5198466243581  98.31000
[INFO   ] Learning rate: 4.634296875E-4
  943.8674877056653 943.8674877056653   99.49000 360.21355230074835  98.91000
[INFO   ] Learning rate: 4.5184394531249994E-4
  774.4299550584021 774.4299550584021   99.60833 361.53465934197885  98.94000
[INFO   ] Learning rate: 4.405478466796874E-4
  549.7189007205901 549.7189007205901   99.73833 372.0552898203656  99.02000
